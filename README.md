Parquet comparator - is a tool which allows to compare parquet datasets, placed in HDFS.Steps to run:----------------------------1. `sbt package`2. Copy `parquet-comparator_***.jar` to cluster node3. Run spark-shell: </br>   ```   spark-shell \   --jars /***/parquet-comparator_***.jar \   --conf spark.driver.args=" \       --firstPath=... \ - #1 parquets path, mandatory       --secondPath=... \ - #2 parquets path, mandatory       --localResultPath=... \ - local node path for comparison report creation, mandatory       --hdfsResultPath=... \ - hdfs dir for data discrepancies, mandatory       --primaryKeys=... \ - rows primary keys (e.g --primaryKeys=firstKey,secondKey,oneAnotherKey), mandatory       --excluded=... \ - columns to ignore during the comparison, optional   "   ```4. Wait for scala-cli loads5. Execute `com.strizhonovapps.prqtcomparator.Runner.compare(sc, sqlContext)`